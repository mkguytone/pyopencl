<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>13.21. 共有ローカルメモリ</title><link rel="stylesheet" type="text/css" href="index.css" /><meta name="generator" content="DocBook XSL Stylesheets V1.79.1" /><link rel="home" href="index.html" title="Python OpenCL入門" /><link rel="up" href="ch13.html" title="Chapter 13. OpenCLの概要" /><link rel="prev" href="ch13s20.html" title="13.20. メモリレイテンシ" /><link rel="next" href="ch13s22.html" title="13.22. Stalls(ストール)" /><meta xmlns="" name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0" /><script xmlns="" type="text/javascript" src="prettify/prettify.js"></script><link xmlns="" rel="stylesheet" type="text/css" href="prettify/skins/sons-of-obsidian.css" /><script xmlns="">
    window.addEventListener("load", function() {
      PR.prettyPrint();
	  });	
	</script><script xmlns="" type="text/javascript" src="script/head.js"></script></head><body><div class="navheader"><table width="100%" summary="Navigation header"><tr><td width="20%" align="left"><a accesskey="p" href="ch13s20.html">Prev</a> </td><th width="60%" align="center"> </th><td width="20%" align="right"> <a accesskey="n" href="ch13s22.html">Next</a></td></tr></table><hr /></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="_共有ローカルメモリ"></a>13.21. 共有ローカルメモリ</h2></div></div></div><p>共有ローカルメモリ（単純にローカルメモリと呼ぶ事が多い）は、物理的に見ればプロセッサの近辺に配置されているため、キャッシュと類似したパフォーマンスを得ることができます。そのためグローバルメモリ（又はコンスタントメモリ）の10倍以上早く処理が可能となります。キャッシュと異なる点としては、アプリケーションが確保するメモリ領域で使用可能なことです。</p><p>ローカルメモリの最大値はOpenCLのデバイス情報取得関数で知ることができます。</p><p>一応補足しますが、ローカルメモリをキャッシュとしても定義上は問題はないと考えられますが、OpenCLはデバイスを抽象化したフレームワークであり、通常こうした物理層のマッピングを開発者が直接行なうことは稀です。</p><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="_intel_第３_４世代以降のcpuアーキテクチャ"></a>13.21.1. Intel（第３~４世代以降のCPUアーキテクチャ）</h3></div></div></div><p>Intelの第３世代、第４世代以降のCPUアーキテクチャでは、同一のダイにCPUコアとGPUコアが集積・併存します。CPUとGPUで効率的にリソースを割り当てるために、LLC（ラストレベルキャッシュ）というCPUとGPUで共有するキャッシュがあり、CPUとGPUコアのLLCはリングバス(ショートカットという最適パスも存在)で接続されています。</p><p>IntelのOpenCL実装がグローバルメモリーにアクセスする場合LLC(Last Level Cache: 2-8MBが目安)またはEDRAM（128MBが目安）を通じておこないます。</p><p>IntelのiGPUでは、共有ローカルメモリはL3キャッシュに存在します。共有ローカルメモリとよぶときはL3キャッシュの一領域を意味します。</p><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_simd_8_16_32の要件"></a>SIMD-8/16/32の要件</h4></div></div></div><p>使用されるSIMDレーン数は、コンパイルされたSIMD幅とローカルワークサイズで決定されます。</p><p>clGetKernelWorkGroupInfo関数の引数で、CL_KERNEL_PREFERRED_WORK_GROUP_SIZE_MULTIPLEフラグを指定すると、コンパイルされたSIMD幅を取得できます。</p><p>この値が32の時はSIMD-32、16のときはSIMD-16、8のときはSIMD-8を使うことが指定されます。ローカルワークサイズはこの数値の倍数としないと、SIMDレーンの使用率はフル稼働されないことになります。</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_cl_kernel_preferred_work_group_size_multiple"></a>CL_KERNEL_PREFERRED_WORK_GROUP_SIZE_MULTIPLE</h4></div></div></div><p>前項で取得するコンパイルしたSIMD幅は、プライベートメモリの数値が閾値をこえると変動します。以下の表に閾値をまとめました。</p><div class="informaltable"><table class="informaltable" cellpadding="4px" style="border-collapse: collapse;border-top: 3px solid #527bbd; border-bottom: 3px solid #527bbd; border-left: 3px solid #527bbd; border-right: 3px solid #527bbd; "><colgroup><col class="col_1" /><col class="col_2" /></colgroup><tbody><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="left" valign="top"><p><span class="strong"><strong>SIMD幅</strong></span></p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p><span class="strong"><strong>プライベートメモリの閾値</strong></span></p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="left" valign="top"><p><span class="strong"><strong>SIMD-8</strong></span></p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p><span class="strong"><strong>512バイト</strong></span></p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="left" valign="top"><p><span class="strong"><strong>SIMD-16</strong></span></p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p><span class="strong"><strong>256バイト</strong></span></p></td></tr><tr><td style="border-right: 1px solid #527bbd; " align="left" valign="top"><p><span class="strong"><strong>SIMD-32</strong></span></p></td><td style="" align="left" valign="top"><p><span class="strong"><strong>128バイト</strong></span></p></td></tr></tbody></table></div><p>プライベートメモリで容量を超える処理をワークアイテムですると、グローバルメモリを使うことになり、これをスピル（こぼれる、溢れ出る）と呼ぶことがあります。</p><p>メモリのスピルは、キャッシュに収まりきらないデータがメインメモリで処理されることの一般的な現象なので、SIMD幅に限定されるわけではありません。メモリのスピルで代表的なものを次の項目で解説します。</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_edramとllc"></a>EDRAMとLLC</h4></div></div></div><div class="note" style="margin-left: 0; margin-right: 10%;"><h3 class="title">Note</h3><p>EDRAMはIntelの一部のハイエンドモデルプロセッサにだけ附属したキャッシュです。</p></div><p>EDRAMはホストメモリのサブシステムとしてカウントされます。128MB以下のバッファはEDRAMに領域を確保します。但し、LLCのサイズ（プロセッサにより異なる:2-8MB）を下回る場合は、LLCに領域を確保します。</p></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="_nvidia"></a>13.21.2. NVIDIA</h3></div></div></div><p>NVIDIAデバイスでコーディングする際にはよくあるのですが、良く仕様を読んで理解していないと、デバイス情報取得関数で戻ってきたローカルメモリサイズの数値が想定より低いケースがあります。</p><p>第２世代Maxwell（GM204）は、第１世代（GM107）に比べて50%増えた共通ローカルメモリを持ちます。GM107が64KBだったのに対して、96KBの共有メモリに増量されています。</p><p>しかしスレッドブロックで使えるローカルメモリは、GM204もGM107も48KBとなります。規格と違うではないかと憤慨した技術者も多いかもしれませんが、そもそもOpenCLのデバイス情報取得関数でローカルメモリサイズを確認してから規格書をよんでいれば、無駄な時間を使わずに開発ができたかもしれません。</p><p>もちろん規格を先によんだ方がいいケースもあります。Fermiアーキテクチャでは、16KBか48KBの選択ができ、L1キャッシュ（16KBか48KB）とメモリ領域の区分けを変えることができます。こうしたレアケースもあることは念頭においたほうがいいでしょう。</p><p>今後もアーキテクチャの世代が更新されるたびにSLMのサイズが変化するのは間違いなく、ローカルメモリサイズは新しいプロセッサを使うたびにOpenCL APIを通じて確認することを推奨します。</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="_amd"></a>13.21.3. AMD</h3></div></div></div><p>GCNにおけるローカルメモリは「Local Data Share」（LDS）が該当します。LDSは各CU（wavefront）に対して32KBから64KBのローカルメモリー領域を確保します。</p></div></div><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="ch13s20.html">Prev</a> </td><td width="20%" align="center"><a accesskey="u" href="ch13.html">Up</a></td><td width="40%" align="right"> <a accesskey="n" href="ch13s22.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top"> </td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top"> </td></tr></table></div><wrapper xmlns=""><p>Copyright 2018-2019, by Masaki Komatsu</p>


</wrapper></body></html>